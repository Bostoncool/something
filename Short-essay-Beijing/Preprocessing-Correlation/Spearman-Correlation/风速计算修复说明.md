# Spearman Correlation Analysis - Wind Speed Calculation Fix Guide

## Fix Overview

This fix references the implementation in the Kendall-Correlation folder and improves wind speed data processing functionality in Spearman-Correlation analysis.

## Main Modifications

### 1. Enhanced `collect_all_meteo_files()` Method

**Modification Location**: Lines 111-138

**Modification Content**:
- Added second file search method: search all CSV files (including wind component data)
- Merge and deduplicate results from two search methods
- Added wind component file statistics and display functionality

**Main Improvements**:
```python
# Method 2: Search all CSV files (including specially named files like wind components)
search_pattern = os.path.join(self.meteo_data_dir, "**", "*.csv")
all_csv_files = glob.glob(search_pattern, recursive=True)

# Merge and deduplicate
all_files_set = set(all_files + all_csv_files)
all_files = list(all_files_set)

# Count wind component files
wind_files = [f for f in all_files if any(wind in os.path.basename(f).lower() 
             for wind in ['u10', 'v10', 'u100', 'v100', 'wind'])]
```

### 2. New `aggregate_spatial_data()` Method

**Location**: Lines 149-178

**Functionality**: Aggregate spatial data, converting multidimensional data (time, latitude, longitude) to time series

**Main Features**:
- Group by time and calculate spatial average
- Automatically identify numeric columns and exclude spatial coordinate columns
- Comprehensive exception handling

### 3. New `process_wind_component_data()` Method

**Location**: Lines 180-218

**Functionality**: Dedicated processing of wind component data

**Main Features**:
- Remove NaN values
- Remove outliers (wind component range: -100 to 100 m/s)
- Sample large datasets (when >50000 data points)
- Return standard statistics (mean, std, min, max)

### 4. Enhanced `calculate_stats_vectorized()` Method

**Location**: Lines 220-265

**Modification Content**:
- Added multidimensional data processing capability (2D and 3D arrays)
- Aggregate spatial data along time dimension
- Remove invalid value handling
- Large dataset sampling optimization (when >10000 data points)

**Core Improvements**:
```python
# Handle multidimensional data - if 2D or 3D array, flatten to 1D
if hourly_data.ndim > 1:
    if hourly_data.ndim == 3:  # (time, lat, lon)
        hourly_data = np.nanmean(hourly_data, axis=(1, 2))
    elif hourly_data.ndim == 2:  # (time, spatial)
        hourly_data = np.nanmean(hourly_data, axis=1)

# Remove invalid values
valid_data = hourly_data[~np.isnan(hourly_data)]

# If data is too large, sample to avoid memory issues
if len(valid_data) > 10000:
    step = len(valid_data) // 10000
    valid_data = valid_data[::step]
```

### 5. Enhanced `process_single_meteo_file()` Method

**Location**: Lines 267-360

**Main Improvements**:

#### 5.1 Multiple Encoding Format Support
```python
try:
    df = pd.read_csv(filepath, encoding='utf-8', comment='#')
except UnicodeDecodeError:
    try:
        df = pd.read_csv(filepath, encoding='gbk', comment='#')
    except UnicodeDecodeError:
        df = pd.read_csv(filepath, encoding='latin-1', comment='#')
```

#### 5.2 Handle CSV Comment Lines
- Added `comment='#'` parameter to automatically skip comment lines
- Handle ParserError exceptions

#### 5.3 Handle Multi-Index Data
```python
if 'time' in df.columns and 'latitude' in df.columns and 'longitude' in df.columns:
    df = self.aggregate_spatial_data(df)
```

#### 5.4 Special Handling for Wind Component Data
```python
elif col in ['u10', 'v10', 'u100', 'v100']:
    # Special handling for wind component data
    daily_stats = self.process_wind_component_data(df, col)
```

#### 5.5 Improved Year-Month Information Extraction
```python
# Try to extract year-month from filename (format: YYYYMM.csv)
if len(filename) >= 6 and filename[:4].isdigit() and filename[4:6].isdigit():
    year = int(filename[:4])
    month = int(filename[4:6])
else:
    # If filename doesn't contain year-month info, try to extract from path
    import re
    match = re.search(r'(\d{4})(\d{2})', filepath)
    if match:
        monthly_stats['year'] = int(match.group(1))
        monthly_stats['month'] = int(match.group(2))
```

#### 5.6 Enhanced Column-Level Exception Handling
```python
except Exception as col_error:
    print(f"Error processing column {col} in {os.path.basename(filepath)}: {col_error}")
    monthly_stats[f'{col}_mean'] = np.nan
    monthly_stats[f'{col}_std'] = np.nan
    monthly_stats[f'{col}_min'] = np.nan
    monthly_stats[f'{col}_max'] = np.nan
```

### 6. Enhanced `prepare_combined_data()` Method

**Location**: Lines 569-580

**New Functionality**:
- Count wind component parameters
- Display wind component parameter list
- Issue warning if wind component data not found

```python
# Count wind component features
wind_features = [col for col in combined_data.columns 
                if any(w in col for w in ['u10', 'v10', 'u100', 'v100'])]

print(f"Number of wind component parameters: {len(wind_features)}")

if wind_features:
    print(f"Wind component parameters: {wind_features}")
else:
    print("Warning: No wind component parameters found in combined data!")
```

## Expected Results

After the fix, the program should be able to:

1. **Correctly identify and load wind component data files**
   - Search for wind component CSV files in subdirectories
   - Display number and examples of wind component files found

2. **Correctly process wind component data**
   - Handle multidimensional arrays (time, latitude, longitude)
   - Remove outliers and NaN values
   - Optimize large datasets through sampling

3. **Display wind component correlation in heatmap**
   - u10_mean, u10_std, u10_min, u10_max
   - v10_mean, v10_std, v10_min, v10_max
   - u100_mean, u100_std, u100_min, u100_max
   - v100_mean, v100_std, v100_min, v100_max

## Running Output Example

After the fix, when running the program you should see output similar to:

```
Found 2280 meteorological data files
  Including 480 wind component related files
  Examples: ['201501.csv', '201502.csv', '201503.csv']

...

Preparing combined data...
Meteorological data shape: (120, 72)
Pollution data shape: (120, 6)
Extra pollution data shape: (120, 8)
Combined data shape: (120, 86)
Final data shape: (120, 86)

Number of meteorological parameters: 72
Number of pollution parameters: 14
Number of wind component parameters: 16
Wind component parameters: ['u10_mean', 'u10_std', 'u10_min', 'u10_max', 
                            'v10_mean', 'v10_std', 'v10_min', 'v10_max',
                            'u100_mean', 'u100_std', 'u100_min', 'u100_max',
                            'v100_mean', 'v100_std', 'v100_min', 'v100_max']
```

## Technical Points

### Main Problems Addressed

1. **File search problem**: Wind component data stored in subdirectories, original code only searched main directory
2. **Data dimension problem**: Wind component data contains multidimensional structure (time×latitude×longitude)
3. **CSV format problem**: CSV files converted from NC contain comment lines
4. **Memory optimization**: Large datasets need sampling to avoid memory overflow
5. **Outlier handling**: Wind component data requires special value range validation

### Performance Optimization

1. **Data Sampling**:
   - Wind component data: Sample when >50000 entries
   - General data: Sample when >10000 entries

2. **Memory Optimization**:
   - Use `downcast` to optimize data types
   - Clean cache promptly

3. **Parallel Processing**:
   - Maintain original multi-process parallel loading functionality

## Notes

1. Ensure wind component data files are in correct subdirectory structure
2. Wind component data should contain correct column names (u10, v10, u100, v100)
3. If data contains spatial dimensions, ensure time, latitude, longitude columns exist
4. Regularly check processing logs to identify data quality issues

## Reference Documents

For more detailed information, refer to:
- `Kendall-Correlation/WIND_DATA_FIX_SUMMARY.md` - Problem analysis and fix solutions
- `Kendall-Correlation/使用说明.md` - Usage guide and verification methods
